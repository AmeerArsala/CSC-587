{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# Paperspace Gradient: TensorFlow 2 Quick Start for Beginners\n",
    "Last modified: Oct 28th 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "This demonstrates TensorFlow 2 usage in a Gradient Notebook. The material is based on the original TensorFlow 2 Beginner Quick Start at https://www.tensorflow.org/tutorials/quickstart/beginner .\n",
    "\n",
    "See the end of the notebook for the original copyright notice and license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "04QgGZc9bF5D"
   },
   "source": [
    "This short introduction uses [Keras](https://www.tensorflow.org/guide/keras/overview) to:\n",
    "\n",
    "1. Build a neural network that classifies images\n",
    "2. Train this neural network\n",
    "3. And, finally, evaluate the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Setup and GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "TensorFlow 2 is already installed in our container, so we can import it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Provided that you have started this Notebook on a [Gradient GPU instance](https://docs.paperspace.com/gradient/more/instance-types), Gradient will see the GPU and TensorFlow will utilize it. Using a GPU provides large speedups for many machine learning models.\n",
    "\n",
    "We can list the available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "By default, TensorFlow allocates all the memory on a GPU to the model being run. This is fine, until, for example, you run a container like this one that has more than one `.ipynb` notebook on it. Then the second notebook's model may fail due to the GPU being out of memory.\n",
    "\n",
    "We can help with this by setting the memory used to [grow as needed](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) rather than being allocated all at once at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "The model shows classification of the handwritten digits 0-9 in the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "The data are loaded, converted from integers to floating-point numbers, and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "7FP5258xjs-v"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "BPZ68wASog_I"
   },
   "source": [
    "The model is a simple single dense layer neural network with 10 output classes. We build it using `tf.keras.Sequential` by stacking layers.\n",
    "\n",
    "Here we separate the model from the step to convert its outputs into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "l2hiez2eIUz8"
   },
   "source": [
    "For each example the model returns a vector of \"[logits](https://developers.google.com/machine-learning/glossary#logits)\" or \"[log-odds](https://developers.google.com/machine-learning/glossary#log-odds)\" scores, one for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "OeOrNdnkEEcR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3020117 ,  0.5922008 , -0.41980827, -0.24884853, -0.8993958 ,\n",
       "         0.25624874,  0.20577453,  0.27147472, -0.08960623,  0.08015168]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "tgjhDQGcIniO"
   },
   "source": [
    "The `tf.nn.softmax` function converts these logits to \"probabilities\" for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "zWSRnQ0WI5eq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07233316, 0.17688417, 0.06429527, 0.07628267, 0.03980126,\n",
       "        0.12641159, 0.1201894 , 0.12835103, 0.08945073, 0.10600073]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "he5u_okAYS4a"
   },
   "source": [
    "(Note: It is possible to bake this `tf.nn.softmax` in as the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to\n",
    "provide an exact and numerically stable loss calculation for all models when using a softmax output.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "hQyugpgRIyrA"
   },
   "source": [
    "To train the network, we choose an optimizer and loss function for training.\n",
    "\n",
    "The `losses.SparseCategoricalCrossentropy` loss takes a vector of logits and a `True` index and returns a scalar loss for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "RSkzdv8MD0tT"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "SfR4MsSDU880"
   },
   "source": [
    "This loss is equal to the negative log probability of the true class:\n",
    "it is zero if the model is sure of the correct class.\n",
    "\n",
    "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to `-tf.math.log(1/10) ~= 2.3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "NJWqEVrrJ7ZB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0682123"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized is the commonly used Adam algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "9foNKHzTD2Vo"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "ix4mEL65on-w"
   },
   "source": [
    "The `Model.fit` method trains the model, adjusting the model parameters to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "y7suUbJXVLqP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2946 - accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1420 - accuracy: 0.9576\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1077 - accuracy: 0.9669\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0868 - accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0751 - accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85b828da00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "4mDAAPFqVVgn"
   },
   "source": [
    "The `Model.evaluate` method checks the model's performance, usually on a \"[Validation-set](https://developers.google.com/machine-learning/glossary#validation-set)\" or \"[Test-set](https://developers.google.com/machine-learning/glossary#test-set)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "F7dTAzgHDUh7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0778 - accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07781801372766495, 0.9758999943733215]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "T4JfEh7kvx6m"
   },
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Aj8NrlzlJqDG"
   },
   "source": [
    "If you want your model to return a probability, you can wrap the trained model, and attach the softmax layer to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "rYb6DrEH0GMv"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "cnqOZtUp1YR_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[9.05479638e-08, 2.39971225e-08, 7.25329392e-06, 5.21020374e-05,\n",
       "        9.41129011e-13, 1.35973721e-07, 2.88683779e-15, 9.99939084e-01,\n",
       "        1.32286630e-07, 1.18476009e-06],\n",
       "       [6.62377460e-08, 8.56510131e-04, 9.98965383e-01, 6.89985391e-05,\n",
       "        1.59924808e-13, 1.07135726e-04, 8.64839507e-08, 1.38364136e-12,\n",
       "        1.86673992e-06, 1.81718200e-11],\n",
       "       [5.31409682e-07, 9.98629928e-01, 9.91037086e-05, 8.31386660e-06,\n",
       "        1.38301475e-04, 8.96011079e-06, 7.86305372e-06, 1.01774547e-03,\n",
       "        8.63065870e-05, 3.13829537e-06],\n",
       "       [9.99995470e-01, 5.50283014e-11, 2.01559897e-06, 1.39250972e-07,\n",
       "        7.29438066e-10, 3.80786986e-07, 4.09131104e-07, 9.36438084e-07,\n",
       "        5.92850269e-10, 7.34547086e-07],\n",
       "       [2.30139221e-06, 3.46859674e-09, 5.36648940e-06, 1.20531212e-07,\n",
       "        9.94976640e-01, 8.31843323e-08, 2.32134653e-07, 1.28873784e-04,\n",
       "        1.43077855e-07, 4.88630775e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "To proceed with TensorFlow 2 in Gradient, you can:\n",
    "    \n",
    " - Try out the quick_start_advanced.ipynb notebook in this same container if you want to see some more advanced usage\n",
    " - Look at other Gradient material, such as the [tutorials](https://docs.paperspace.com/gradient/get-started/tutorials-list), [ML Showcase](https://ml-showcase.paperspace.com), [blog](https://blog.paperspace.com), or [community](https://community.paperspace.com)\n",
    " - Start writing your own projects, using our [documentation](https://docs.paperspace.com/gradient) when needed\n",
    " \n",
    "If you get stuck or need help, [contact support](https://support.paperspace.com), and we will be happy to assist.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original TensorFlow copyright notice and license\n",
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "form",
    "gradient": {
     "editing": false
    },
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
