{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868428a6-b4b7-4e26-8c11-0b8cf1dacb25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:19:48.920499Z",
     "iopub.status.busy": "2024-01-27T09:19:48.919425Z",
     "iopub.status.idle": "2024-01-27T09:19:48.925090Z",
     "shell.execute_reply": "2024-01-27T09:19:48.924002Z",
     "shell.execute_reply.started": "2024-01-27T09:19:48.920454Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import scipy\n",
    "\n",
    "# data viz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "606d53fe-f4e8-4506-b78a-1e23811835fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:20:07.967947Z",
     "iopub.status.busy": "2024-01-27T09:20:07.967576Z",
     "iopub.status.idle": "2024-01-27T09:20:08.487256Z",
     "shell.execute_reply": "2024-01-27T09:20:08.486466Z",
     "shell.execute_reply.started": "2024-01-27T09:20:07.967918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
       " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST\n",
    "data = keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3c8a1b-6466-431b-9533-e754e98a12c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:20:11.998580Z",
     "iopub.status.busy": "2024-01-27T09:20:11.998142Z",
     "iopub.status.idle": "2024-01-27T09:20:12.004123Z",
     "shell.execute_reply": "2024-01-27T09:20:12.003260Z",
     "shell.execute_reply.started": "2024-01-27T09:20:11.998553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_ideal, y_ideal) = data\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a1a47c-bb1f-4673-96a1-e18ded549430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:20:20.309189Z",
     "iopub.status.busy": "2024-01-27T09:20:20.308258Z",
     "iopub.status.idle": "2024-01-27T09:20:20.495228Z",
     "shell.execute_reply": "2024-01-27T09:20:20.494272Z",
     "shell.execute_reply.started": "2024-01-27T09:20:20.309159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff6a0cf68f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03c8742-c493-4bf3-8128-c0fd833137ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:20:40.518963Z",
     "iopub.status.busy": "2024-01-27T09:20:40.518554Z",
     "iopub.status.idle": "2024-01-27T09:20:40.525126Z",
     "shell.execute_reply": "2024-01-27T09:20:40.524322Z",
     "shell.execute_reply.started": "2024-01-27T09:20:40.518933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06786f11-afd4-44e3-8852-b6ed4c9d1498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:21:01.462839Z",
     "iopub.status.busy": "2024-01-27T09:21:01.462408Z",
     "iopub.status.idle": "2024-01-27T09:21:01.468093Z",
     "shell.execute_reply": "2024-01-27T09:21:01.467015Z",
     "shell.execute_reply.started": "2024-01-27T09:21:01.462810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_ideal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "389f794a-d402-48d3-a425-69ab157972f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:21:09.605629Z",
     "iopub.status.busy": "2024-01-27T09:21:09.605245Z",
     "iopub.status.idle": "2024-01-27T09:21:09.729421Z",
     "shell.execute_reply": "2024-01-27T09:21:09.728473Z",
     "shell.execute_reply.started": "2024-01-27T09:21:09.605601Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale the images in the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_ideal = X_ideal.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122bc7bb-4ce9-46dc-9809-c144d608e43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T09:21:32.808064Z",
     "iopub.status.busy": "2024-01-27T09:21:32.807254Z",
     "iopub.status.idle": "2024-01-27T10:20:24.190966Z",
     "shell.execute_reply": "2024-01-27T10:20:24.190045Z",
     "shell.execute_reply.started": "2024-01-27T09:21:32.808036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 1.9620 - val_loss: 1.3983\n",
      "Epoch 2/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 1.1646 - val_loss: 1.1083\n",
      "Epoch 3/200\n",
      "540/540 [==============================] - 16s 30ms/step - loss: 0.8738 - val_loss: 0.7078\n",
      "Epoch 4/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.7047 - val_loss: 0.5820\n",
      "Epoch 5/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.5985 - val_loss: 0.5216\n",
      "Epoch 6/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.5229 - val_loss: 0.4355\n",
      "Epoch 7/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.4693 - val_loss: 0.4134\n",
      "Epoch 8/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.4299 - val_loss: 0.3578\n",
      "Epoch 9/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.3917 - val_loss: 0.3413\n",
      "Epoch 10/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.3608 - val_loss: 0.3062\n",
      "Epoch 11/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.3329 - val_loss: 0.4704\n",
      "Epoch 12/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.3044 - val_loss: 0.2594\n",
      "Epoch 13/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.2845 - val_loss: 0.2469\n",
      "Epoch 14/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.2649 - val_loss: 0.2381\n",
      "Epoch 15/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.2478 - val_loss: 0.2444\n",
      "Epoch 16/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.2314 - val_loss: 0.2069\n",
      "Epoch 17/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.2189 - val_loss: 0.1986\n",
      "Epoch 18/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.2058 - val_loss: 0.1971\n",
      "Epoch 19/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.1956 - val_loss: 0.1940\n",
      "Epoch 20/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.1876 - val_loss: 0.1887\n",
      "Epoch 21/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1784 - val_loss: 0.1853\n",
      "Epoch 22/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.1718 - val_loss: 0.1753\n",
      "Epoch 23/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.1636 - val_loss: 0.1854\n",
      "Epoch 24/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1570 - val_loss: 0.1768\n",
      "Epoch 25/200\n",
      "540/540 [==============================] - 18s 32ms/step - loss: 0.1510 - val_loss: 0.1569\n",
      "Epoch 26/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1456 - val_loss: 0.1721\n",
      "Epoch 27/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1401 - val_loss: 0.1594\n",
      "Epoch 28/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.1348 - val_loss: 0.1556\n",
      "Epoch 29/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.1311 - val_loss: 0.1747\n",
      "Epoch 30/200\n",
      "540/540 [==============================] - 18s 32ms/step - loss: 0.1267 - val_loss: 0.1546\n",
      "Epoch 31/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1222 - val_loss: 0.1489\n",
      "Epoch 32/200\n",
      "540/540 [==============================] - 19s 34ms/step - loss: 0.1181 - val_loss: 0.1458\n",
      "Epoch 33/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1166 - val_loss: 0.1584\n",
      "Epoch 34/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1119 - val_loss: 0.1514\n",
      "Epoch 35/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1082 - val_loss: 0.1775\n",
      "Epoch 36/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.1050 - val_loss: 0.1485\n",
      "Epoch 37/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1026 - val_loss: 0.1436\n",
      "Epoch 38/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0999 - val_loss: 0.1346\n",
      "Epoch 39/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0953 - val_loss: 0.1426\n",
      "Epoch 40/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0929 - val_loss: 0.1314\n",
      "Epoch 41/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0925 - val_loss: 0.1364\n",
      "Epoch 42/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0893 - val_loss: 0.1384\n",
      "Epoch 43/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0861 - val_loss: 0.1329\n",
      "Epoch 44/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0846 - val_loss: 0.1378\n",
      "Epoch 45/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0811 - val_loss: 0.1387\n",
      "Epoch 46/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0793 - val_loss: 0.1469\n",
      "Epoch 47/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0782 - val_loss: 0.1291\n",
      "Epoch 48/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0764 - val_loss: 0.1373\n",
      "Epoch 49/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0730 - val_loss: 0.1327\n",
      "Epoch 50/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0726 - val_loss: 0.1396\n",
      "Epoch 51/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0687 - val_loss: 0.1371\n",
      "Epoch 52/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0688 - val_loss: 0.1253\n",
      "Epoch 53/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0672 - val_loss: 0.1331\n",
      "Epoch 54/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0658 - val_loss: 0.1419\n",
      "Epoch 55/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0637 - val_loss: 0.1291\n",
      "Epoch 56/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0615 - val_loss: 0.1337\n",
      "Epoch 57/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0603 - val_loss: 0.1535\n",
      "Epoch 58/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0592 - val_loss: 0.1279\n",
      "Epoch 59/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0574 - val_loss: 0.1466\n",
      "Epoch 60/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0568 - val_loss: 0.1338\n",
      "Epoch 61/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0537 - val_loss: 0.1350\n",
      "Epoch 62/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0534 - val_loss: 0.1308\n",
      "Epoch 63/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0521 - val_loss: 0.1551\n",
      "Epoch 64/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0509 - val_loss: 0.1283\n",
      "Epoch 65/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0494 - val_loss: 0.1394\n",
      "Epoch 66/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0478 - val_loss: 0.1316\n",
      "Epoch 67/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0476 - val_loss: 0.1297\n",
      "Epoch 68/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0461 - val_loss: 0.1311\n",
      "Epoch 69/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0464 - val_loss: 0.1440\n",
      "Epoch 70/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0441 - val_loss: 0.1328\n",
      "Epoch 71/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0431 - val_loss: 0.1382\n",
      "Epoch 72/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0425 - val_loss: 0.1310\n",
      "Epoch 73/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0405 - val_loss: 0.1460\n",
      "Epoch 74/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0411 - val_loss: 0.1370\n",
      "Epoch 75/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0388 - val_loss: 0.1426\n",
      "Epoch 76/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0389 - val_loss: 0.1447\n",
      "Epoch 77/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0376 - val_loss: 0.1405\n",
      "Epoch 78/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0368 - val_loss: 0.1347\n",
      "Epoch 79/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0344 - val_loss: 0.1400\n",
      "Epoch 80/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0340 - val_loss: 0.1396\n",
      "Epoch 81/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0337 - val_loss: 0.1326\n",
      "Epoch 82/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0326 - val_loss: 0.1456\n",
      "Epoch 83/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0323 - val_loss: 0.1552\n",
      "Epoch 84/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0320 - val_loss: 0.1393\n",
      "Epoch 85/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0304 - val_loss: 0.1418\n",
      "Epoch 86/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0299 - val_loss: 0.1407\n",
      "Epoch 87/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0296 - val_loss: 0.1418\n",
      "Epoch 88/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0280 - val_loss: 0.1465\n",
      "Epoch 89/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0289 - val_loss: 0.1482\n",
      "Epoch 90/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0277 - val_loss: 0.1427\n",
      "Epoch 91/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0280 - val_loss: 0.1483\n",
      "Epoch 92/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0263 - val_loss: 0.1477\n",
      "Epoch 93/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0251 - val_loss: 0.1659\n",
      "Epoch 94/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0255 - val_loss: 0.1651\n",
      "Epoch 95/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0245 - val_loss: 0.1441\n",
      "Epoch 96/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0234 - val_loss: 0.1458\n",
      "Epoch 97/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0234 - val_loss: 0.1521\n",
      "Epoch 98/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0214 - val_loss: 0.1487\n",
      "Epoch 99/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0212 - val_loss: 0.1494\n",
      "Epoch 100/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0214 - val_loss: 0.1512\n",
      "Epoch 101/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0208 - val_loss: 0.1553\n",
      "Epoch 102/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0213 - val_loss: 0.1486\n",
      "Epoch 103/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0198 - val_loss: 0.1559\n",
      "Epoch 104/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0188 - val_loss: 0.1553\n",
      "Epoch 105/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0195 - val_loss: 0.1587\n",
      "Epoch 106/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0198 - val_loss: 0.1503\n",
      "Epoch 107/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0203 - val_loss: 0.1518\n",
      "Epoch 108/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0175 - val_loss: 0.1551\n",
      "Epoch 109/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0173 - val_loss: 0.1539\n",
      "Epoch 110/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0167 - val_loss: 0.1607\n",
      "Epoch 111/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0168 - val_loss: 0.1574\n",
      "Epoch 112/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0159 - val_loss: 0.1591\n",
      "Epoch 113/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0172 - val_loss: 0.1682\n",
      "Epoch 114/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0147 - val_loss: 0.1668\n",
      "Epoch 115/200\n",
      "540/540 [==============================] - 16s 30ms/step - loss: 0.0176 - val_loss: 0.1604\n",
      "Epoch 116/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0148 - val_loss: 0.1678\n",
      "Epoch 117/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0143 - val_loss: 0.1711\n",
      "Epoch 118/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0144 - val_loss: 0.1691\n",
      "Epoch 119/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0137 - val_loss: 0.1643\n",
      "Epoch 120/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0121 - val_loss: 0.1696\n",
      "Epoch 121/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0125 - val_loss: 0.1716\n",
      "Epoch 122/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0119 - val_loss: 0.1685\n",
      "Epoch 123/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0113 - val_loss: 0.1676\n",
      "Epoch 124/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0119 - val_loss: 0.1714\n",
      "Epoch 125/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0110 - val_loss: 0.1748\n",
      "Epoch 126/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0132 - val_loss: 0.1812\n",
      "Epoch 127/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0113 - val_loss: 0.1756\n",
      "Epoch 128/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0105 - val_loss: 0.1758\n",
      "Epoch 129/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0100 - val_loss: 0.1736\n",
      "Epoch 130/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0102 - val_loss: 0.1731\n",
      "Epoch 131/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0109 - val_loss: 0.1766\n",
      "Epoch 132/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0105 - val_loss: 0.1746\n",
      "Epoch 133/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0094 - val_loss: 0.1839\n",
      "Epoch 134/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0102 - val_loss: 0.1779\n",
      "Epoch 135/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0094 - val_loss: 0.1824\n",
      "Epoch 136/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0084 - val_loss: 0.1834\n",
      "Epoch 137/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0083 - val_loss: 0.1861\n",
      "Epoch 138/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0085 - val_loss: 0.1867\n",
      "Epoch 139/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0077 - val_loss: 0.1827\n",
      "Epoch 140/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0097 - val_loss: 0.1956\n",
      "Epoch 141/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 1.2911 - val_loss: 0.4720\n",
      "Epoch 142/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.3544 - val_loss: 0.2378\n",
      "Epoch 143/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.2296 - val_loss: 0.1997\n",
      "Epoch 144/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1821 - val_loss: 0.2036\n",
      "Epoch 145/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1555 - val_loss: 0.1712\n",
      "Epoch 146/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1379 - val_loss: 0.1514\n",
      "Epoch 147/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.1231 - val_loss: 0.1433\n",
      "Epoch 148/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1143 - val_loss: 0.1424\n",
      "Epoch 149/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.1059 - val_loss: 0.1453\n",
      "Epoch 150/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0992 - val_loss: 0.1308\n",
      "Epoch 151/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0921 - val_loss: 0.1422\n",
      "Epoch 152/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0870 - val_loss: 0.1301\n",
      "Epoch 153/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0809 - val_loss: 0.1360\n",
      "Epoch 154/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0777 - val_loss: 0.1404\n",
      "Epoch 155/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0749 - val_loss: 0.1365\n",
      "Epoch 156/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0709 - val_loss: 0.1289\n",
      "Epoch 157/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0677 - val_loss: 0.1377\n",
      "Epoch 158/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0654 - val_loss: 0.1316\n",
      "Epoch 159/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0622 - val_loss: 0.1257\n",
      "Epoch 160/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0597 - val_loss: 0.1211\n",
      "Epoch 161/200\n",
      "540/540 [==============================] - 16s 30ms/step - loss: 0.0573 - val_loss: 0.1245\n",
      "Epoch 162/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0556 - val_loss: 0.1242\n",
      "Epoch 163/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0539 - val_loss: 0.1253\n",
      "Epoch 164/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0514 - val_loss: 0.1236\n",
      "Epoch 165/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0489 - val_loss: 0.1302\n",
      "Epoch 166/200\n",
      "540/540 [==============================] - 18s 32ms/step - loss: 0.0475 - val_loss: 0.1327\n",
      "Epoch 167/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0466 - val_loss: 0.1222\n",
      "Epoch 168/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0446 - val_loss: 0.1343\n",
      "Epoch 169/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0434 - val_loss: 0.1292\n",
      "Epoch 170/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0411 - val_loss: 0.1329\n",
      "Epoch 171/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0395 - val_loss: 0.1534\n",
      "Epoch 172/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0393 - val_loss: 0.1324\n",
      "Epoch 173/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0382 - val_loss: 0.1341\n",
      "Epoch 174/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0362 - val_loss: 0.1296\n",
      "Epoch 175/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0346 - val_loss: 0.1285\n",
      "Epoch 176/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0337 - val_loss: 0.1404\n",
      "Epoch 177/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0327 - val_loss: 0.1328\n",
      "Epoch 178/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0321 - val_loss: 0.1312\n",
      "Epoch 179/200\n",
      "540/540 [==============================] - 16s 30ms/step - loss: 0.0305 - val_loss: 0.1331\n",
      "Epoch 180/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0303 - val_loss: 0.1494\n",
      "Epoch 181/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0295 - val_loss: 0.1611\n",
      "Epoch 182/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0284 - val_loss: 0.1421\n",
      "Epoch 183/200\n",
      "540/540 [==============================] - 18s 32ms/step - loss: 0.0281 - val_loss: 0.1484\n",
      "Epoch 184/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0272 - val_loss: 0.1358\n",
      "Epoch 185/200\n",
      "540/540 [==============================] - 18s 34ms/step - loss: 0.0258 - val_loss: 0.1406\n",
      "Epoch 186/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0246 - val_loss: 0.1384\n",
      "Epoch 187/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0238 - val_loss: 0.1488\n",
      "Epoch 188/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0236 - val_loss: 0.1375\n",
      "Epoch 189/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0234 - val_loss: 0.1522\n",
      "Epoch 190/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0217 - val_loss: 0.1514\n",
      "Epoch 191/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0210 - val_loss: 0.1496\n",
      "Epoch 192/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0203 - val_loss: 0.1532\n",
      "Epoch 193/200\n",
      "540/540 [==============================] - 17s 31ms/step - loss: 0.0201 - val_loss: 0.1529\n",
      "Epoch 194/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0189 - val_loss: 0.1426\n",
      "Epoch 195/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0185 - val_loss: 0.1476\n",
      "Epoch 196/200\n",
      "540/540 [==============================] - 17s 32ms/step - loss: 0.0185 - val_loss: 0.1537\n",
      "Epoch 197/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0180 - val_loss: 0.1570\n",
      "Epoch 198/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0173 - val_loss: 0.1562\n",
      "Epoch 199/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0172 - val_loss: 0.1561\n",
      "Epoch 200/200\n",
      "540/540 [==============================] - 18s 33ms/step - loss: 0.0163 - val_loss: 0.1556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff6a0285720>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Activation, MaxPooling2D, Flatten, Dense, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# Wanted to challenge myself, wasn't sure if it was ok, so I left it like this in a comment :)\n",
    "'''\n",
    "# Instantiated like so: `ConvBlock(50)` and `ConvBlock(20)`\n",
    "class ConvBlock(keras.layers.Layer):\n",
    "  def __init__(self, units: int):\n",
    "    super().__init__()\n",
    "    self.conv = Conv2D(units, kernel_size=(5, 5), padding=\"valid\")\n",
    "    self.activation_func = Activation(\"relu\")\n",
    "    self.max_pool = MaxPooling2D(pool_size=(2, 2), strides=2)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.conv(inputs)\n",
    "    x = self.activation_func(x)\n",
    "    x_ = self.max_pool(x)\n",
    "\n",
    "    return x_ \n",
    "'''\n",
    "\n",
    "# Model time! (LeNet)\n",
    "model = Sequential([\n",
    "    Input(shape=(28, 28)),\n",
    "    Reshape(target_shape=(28, 28, 1)),\n",
    "    \n",
    "    # Conv Block 1\n",
    "    Conv2D(50, kernel_size=(5, 5), padding=\"valid\"),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    # Conv Block 2\n",
    "    Conv2D(20, kernel_size=(5, 5), padding=\"valid\"),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    # Flatten\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(200, activation=\"relu\"),\n",
    "    Dense(2, activation=\"linear\"),  # \"embedding\" layer for visualization\n",
    "\n",
    "    Dense(10, activation=\"softmax\")  # not logits ;_;\n",
    "])\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(), optimizer=SGD(learning_rate=0.01))\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=200, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccbb4887-f2be-4568-bfed-ba02d4f54887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T10:29:13.264425Z",
     "iopub.status.busy": "2024-01-27T10:29:13.263620Z",
     "iopub.status.idle": "2024-01-27T10:29:13.426680Z",
     "shell.execute_reply": "2024-01-27T10:29:13.425758Z",
     "shell.execute_reply.started": "2024-01-27T10:29:13.264394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7ff64dc09f90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "tf.keras.models.load_model(\"lenet.keras\")\n",
    "#model.save(\"lenet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a95986-8661-4649-b535-50895e77613b",
   "metadata": {},
   "source": [
    "# Part II: Exploring the Learned Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de940dc-7760-4633-8b92-18b7fbfafd30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T10:20:24.192660Z",
     "iopub.status.busy": "2024-01-27T10:20:24.192393Z",
     "iopub.status.idle": "2024-01-27T10:20:24.220743Z",
     "shell.execute_reply": "2024-01-27T10:20:24.219960Z",
     "shell.execute_reply.started": "2024-01-27T10:20:24.192632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 24, 24, 50)        1300      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 24, 24, 50)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 50)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 20)          25020     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8, 8, 20)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 20)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               64200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 402       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90952 (355.28 KB)\n",
      "Trainable params: 90952 (355.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "041c6bcf-d285-43c9-9972-687de3311eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T10:20:24.222013Z",
     "iopub.status.busy": "2024-01-27T10:20:24.221699Z",
     "iopub.status.idle": "2024-01-27T10:20:24.227732Z",
     "shell.execute_reply": "2024-01-27T10:20:24.226851Z",
     "shell.execute_reply.started": "2024-01-27T10:20:24.221987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.layers.reshaping.reshape.Reshape at 0x7ff6a0cbbd00>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7ff6a0451ab0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x7ff6a04525f0>,\n",
       " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7ff6a03443d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7ff6a0344700>,\n",
       " <keras.src.layers.core.activation.Activation at 0x7ff6a03447f0>,\n",
       " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7ff6a0344e20>,\n",
       " <keras.src.layers.reshaping.flatten.Flatten at 0x7ff6a03450f0>,\n",
       " <keras.src.layers.core.dense.Dense at 0x7ff6a0345390>,\n",
       " <keras.src.layers.core.dense.Dense at 0x7ff6a0345780>,\n",
       " <keras.src.layers.core.dense.Dense at 0x7ff6a0345b40>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fe313-f73b-46b9-9fb4-d708df520f8a",
   "metadata": {},
   "source": [
    "Show (as images) the filter matrices learned in the first layer of the network.  What do they look like?  Alternately, show as images the result of the first layer of filters on some input images.  What does the network seem to be looking for in the input images?  (To access the filter weights, use model.layers[0].weights[0]).  \n",
    "\n",
    "**The network seems to be looking for tiny features like edges which would translate to parts of handwritten digits from the input images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7baffa1c-2a3f-49c9-85a8-412f0ac697c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T10:20:24.229767Z",
     "iopub.status.busy": "2024-01-27T10:20:24.229215Z",
     "iopub.status.idle": "2024-01-27T10:20:25.042795Z",
     "shell.execute_reply": "2024-01-27T10:20:25.042047Z",
     "shell.execute_reply.started": "2024-01-27T10:20:24.229739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "(rows, cols) = (5, 5)\n",
    "\n",
    "for i in range(rows*cols):\n",
    "  fig.add_subplot(rows, cols, i+1)\n",
    "  plt.imshow(np.reshape(model.layers[1].weights[0], (5, 5, 50))[:, :, i], cmap=\"gray\")\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c30d92-2d71-4c54-bc62-e3a718b1ac57",
   "metadata": {},
   "source": [
    "Visualize the embedding learned by the network.  (In other words, make a scatter plot of the 2D embedding vectors produced by the network when given the training images as input.)  What shape does the embedding have?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a95df918-ba33-496f-b307-1214865a8841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T10:20:25.043957Z",
     "iopub.status.busy": "2024-01-27T10:20:25.043705Z",
     "iopub.status.idle": "2024-01-27T10:20:36.743398Z",
     "shell.execute_reply": "2024-01-27T10:20:36.742254Z",
     "shell.execute_reply.started": "2024-01-27T10:20:25.043929Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 10:20:25.280257: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6912000000 exceeds 10% of free system memory.\n",
      "2024-01-27 10:20:27.270046: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6912000000 exceeds 10% of free system memory.\n",
      "2024-01-27 10:20:30.013647: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6912000000 exceeds 10% of free system memory.\n",
      "2024-01-27 10:20:31.589032: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1728000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m     x_ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[i](x_)\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x_\n\u001b[0;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:3684\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3665\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[1;32m   3666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[1;32m   3667\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3682\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3683\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PathCollection:\n\u001b[0;32m-> 3684\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3686\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3687\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3694\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3696\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplotnonfinite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotnonfinite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3701\u001b[0m     sci(__ret)\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:4652\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4650\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[1;32m   4651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m-> 4652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4655\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_internal.classic_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   4656\u001b[0m          mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_embeddings(x):\n",
    "  x_ = x\n",
    "  for i in range(len(model.layers) - 1):\n",
    "    x_ = model.layers[i](x_)\n",
    "  \n",
    "  return x_\n",
    "\n",
    "\n",
    "plt.scatter(X_train[0], generate_embeddings(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6c4e5-b98e-4c80-b7ce-1d1bfbfa0c34",
   "metadata": {},
   "source": [
    "Take an example of each digit and rotate it in 15 degree increments (scipy.ndimage.rotate).  Run the classifier on each rotated image and see what happens to their class probabilities.  We would assume that an upside down 6 will be classified as a 9.  But what happens in between?  What does an upside down 2 get classified as?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e3d55-d9a0-41d1-9c7a-aef370f62553",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-27T10:20:36.744352Z",
     "iopub.status.idle": "2024-01-27T10:20:36.744678Z",
     "shell.execute_reply": "2024-01-27T10:20:36.744532Z",
     "shell.execute_reply.started": "2024-01-27T10:20:36.744516Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "# 15 * 24 = 360\n",
    "# shape: (10, 24, 15, 28, 28)\n",
    "# each index points to an index of the training set that is said index as the label\n",
    "indices = [list(y_train).index(i) for i in range(10)]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "(rows, cols) = (10, 24)\n",
    "\n",
    "# start @ -1 to cover base case\n",
    "n = -1\n",
    "for i in range(rows*cols):\n",
    "  j = i % 24\n",
    "\n",
    "  # every 24 rotations, new n\n",
    "  if j == 0:\n",
    "    n = n + 1\n",
    "  \n",
    "  digit_index = indices[j]\n",
    "\n",
    "  rotated_image = ndimage.rotate(y_train[digit_index], j * 15)\n",
    "  fig.add_subplot(rows, cols, i+1)\n",
    "  plt.imshow(np.reshape(model.layers[1].weights[0], (5, 5, 50))[:, :, i], cmap=\"gray\")\n",
    "  plt.axis('off')\n",
    "  plt.title(model.predict(rotated_image))\n",
    "\n",
    "  # Every 24 rotations, \n",
    "  if (i + 1) % 24 == 0:\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151d651-84b7-41f1-b879-0d8f18f81e38",
   "metadata": {},
   "source": [
    "How could you make a neural network that is invariant to rotation?  You don't need to implement this, just give one or two ideas for how you could do it.\n",
    "\n",
    "**Data Augmentation - train the network with rotated versions of the image so that it learns to classify images in a way that is invariant to rotation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a03acf-65b2-4f86-bbb7-6e051956b2b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T10:31:28.196765Z",
     "iopub.status.busy": "2024-01-27T10:31:28.196380Z",
     "iopub.status.idle": "2024-01-27T10:31:28.689152Z",
     "shell.execute_reply": "2024-01-27T10:31:28.687867Z",
     "shell.execute_reply.started": "2024-01-27T10:31:28.196735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST.ipynb  lenet.h5  lenet.keras\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336966dd-a582-45ed-9f5d-f146617e85c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
